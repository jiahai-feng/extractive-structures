{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"GOvJgw\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.6.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"GOvJgw\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"GOvJgw\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "from exults.log_utils import Logger\n",
    "\n",
    "from extractive_structures import ROOT\n",
    "from pathlib import Path\n",
    "import exults.run_manager as rm\n",
    "import json\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from exults.slurm_utils import JobsWatcher\n",
    "\n",
    "import exults.plot_utils as pu\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lets_plot as lp\n",
    "lp.LetsPlot.setup_html()\n",
    "\n",
    "from exults.tensorial import Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expts_root = Path(ROOT) / 'paper_experiments'\n",
    "output_root = Path(ROOT) / 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sbatch(config_path, num_devices, slurm_path, node, preassign=False, dry_run=False):\n",
    "    if preassign:\n",
    "        output_path = rm.get_run_dir(\n",
    "            config_path=config_path,\n",
    "            runs_root=output_root,\n",
    "            experiments_root=expts_root,\n",
    "        )\n",
    "        print(f'Preassigning output dir to {output_path}')\n",
    "        preassign_dict = {'RM_OUTPUT_DIR': str(output_path)}\n",
    "    else:\n",
    "        preassign_dict = {}\n",
    "    \n",
    "    flags = [ f'--gres=gpu:{num_devices}', f'-w {node}']\n",
    "    slurm_cmd = ['sbatch', *flags , slurm_path]\n",
    "    if dry_run:\n",
    "        print(f'CONFIG_FILE={config_path} ' + ' '.join(slurm_cmd))\n",
    "        return\n",
    "    try:\n",
    "        slurm_output = subprocess.run(\n",
    "            slurm_cmd, \n",
    "            env={\n",
    "                **os.environ, \n",
    "                'CONFIG_FILE': config_path, \n",
    "                **preassign_dict, \n",
    "                'CUDA_VISIBLE_DEVICES': ','.join([str(i) for i in range(num_devices)]),\n",
    "                'TRANSFORMERS_CACHE': ''\n",
    "            }, \n",
    "            capture_output=True, \n",
    "            check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(e.stdout)\n",
    "        print(e.stderr)\n",
    "        raise e\n",
    "    print(' '.join(slurm_cmd), slurm_output.stdout, slurm_output.stderr)\n",
    "    string = slurm_output.stdout\n",
    "    if not isinstance(string, str):\n",
    "        string = string.decode()\n",
    "    job_id = re.search(r\"job (?P<id>[0-9]+)\", string).group(\"id\")\n",
    "    if preassign:\n",
    "        return job_id, output_path\n",
    "    else:\n",
    "        return job_id\n",
    "\n",
    "def get_last_output(cfg_path, _output_root=None, _expts_root=None):\n",
    "    if _output_root is None:\n",
    "        _output_root = output_root\n",
    "    if _expts_root is None:\n",
    "        _expts_root = expts_root\n",
    "    parent_dir = Path(rm.get_run_dir_parent(cfg_path, _output_root, _expts_root))\n",
    "    dirs = [d for d in os.listdir(parent_dir)  if os.path.isdir(parent_dir / d)]\n",
    "    success_dir = [d for d in dirs if 'done.out' in os.listdir(parent_dir / d)]\n",
    "    max_run = max(int(d) for d in dirs)\n",
    "    max_success = max(int(d) for d in success_dir)\n",
    "    if max_run != max_success:\n",
    "        print(f'Warning: latest run {max_run} of {cfg_path} is not successful. Falling back to {max_success}')\n",
    "    return parent_dir / str(max_success)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tags = ['gemma_27b', 'llama_1b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/fjiahai/extractive_structures/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/fjiahai/extractive_structures/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import extractive_structures.scripts.eval_ocr as eval_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1e-6, 3e-6, 1e-5, 3e-5]\n",
    "epochses = [4, 8, 12, 16]\n",
    "cfgs = []\n",
    "for lr in lrs:\n",
    "    for epochs in epochses:\n",
    "        for model_tag in model_tags:\n",
    "            cfg = eval_ocr.Cfg(\n",
    "                model_tag=model_tag,\n",
    "                lr=lr,\n",
    "                epochs=epochs,\n",
    "                seeds=[0, 1, 2, 3, 4],\n",
    "                half_precision=(model_tag == 'gemma_27b')\n",
    "            )\n",
    "            cfg_path = expts_root / 'sweep_all' / f'full_{model_tag}_{lr}_{epochs}.yaml'\n",
    "            cfg.save(\n",
    "                cfg_path,\n",
    "                meta_kwargs=dict(\n",
    "                    _experiments_root=str(expts_root), \n",
    "                    _output_root=str(output_root)\n",
    "                )\n",
    "            )\n",
    "            cfgs.append({\n",
    "                'lr': lr,\n",
    "                'model_tag': model_tag, \n",
    "                'epochs': epochs,\n",
    "                'cfg_path': cfg_path\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661024\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661025\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661026\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661027\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661028\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661029\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661030\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661031\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661032\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661033\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661034\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661035\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661036\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661037\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661038\\n' b''\n",
      "sbatch --gres=gpu:8 -w saruman /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661039\\n' b''\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for cfg in cfgs:\n",
    "    if cfg['model_tag'] == 'llama_1b':\n",
    "        num_devices = 4\n",
    "        node = 'balrog'\n",
    "        continue\n",
    "    else:\n",
    "        num_devices = 8\n",
    "        node = 'saruman'\n",
    "    job_id = run_sbatch(\n",
    "        cfg['cfg_path'],\n",
    "        num_devices=num_devices, \n",
    "        node=node,\n",
    "        slurm_path=str(ROOT/'slurm/eval_ocr.sh'),\n",
    "        dry_run=False\n",
    "    )\n",
    "    jobs.append({** cfg, 'job_id': job_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patching my mistake\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1e-6, 3e-6, 1e-5, 3e-5]\n",
    "epochses = [4, 8, 12, 16]\n",
    "patch_cfgs = []\n",
    "for lr in lrs:\n",
    "    for epochs in epochses:\n",
    "        for model_tag in model_tags:\n",
    "            if model_tag != 'llama_1b':\n",
    "                continue\n",
    "            cfg = eval_ocr.Cfg(\n",
    "                model_tag=model_tag,\n",
    "                lr=lr,\n",
    "                epochs=epochs,\n",
    "                seeds=[0, 1, 2, 3, 4],\n",
    "                half_precision=(model_tag == 'gemma_27b'),\n",
    "                patch_only=True\n",
    "            )\n",
    "            cfg_path = expts_root / 'sweep_all' / f'full_{model_tag}_{lr}_{epochs}.yaml'\n",
    "            cfg.save(\n",
    "                cfg_path,\n",
    "                meta_kwargs=dict(\n",
    "                    _experiments_root=str(expts_root), \n",
    "                    _output_dir=str(get_last_output(cfg_path))\n",
    "                )\n",
    "            )\n",
    "            patch_cfgs.append({\n",
    "                'lr': lr,\n",
    "                'model_tag': model_tag, \n",
    "                'epochs': epochs,\n",
    "                'cfg_path': cfg_path\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661161\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661162\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661163\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661164\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661165\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661166\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661167\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661168\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661169\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661170\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661171\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661172\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661173\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661174\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661175\\n' b''\n",
      "sbatch --gres=gpu:4 -w balrog /data/fjiahai/extractive_structures/slurm/eval_ocr.sh b'Submitted batch job 1661176\\n' b''\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for cfg in patch_cfgs:\n",
    "    if cfg['model_tag'] == 'llama_1b':\n",
    "        num_devices = 4\n",
    "        node = 'balrog'\n",
    "    else:\n",
    "        num_devices = 8\n",
    "        node = 'saruman'\n",
    "        continue\n",
    "    job_id = run_sbatch(\n",
    "        cfg['cfg_path'],\n",
    "        num_devices=num_devices, \n",
    "        node=node,\n",
    "        slurm_path=str(ROOT/'slurm/eval_ocr.sh'),\n",
    "        dry_run=False\n",
    "    )\n",
    "    jobs.append({** cfg, 'job_id': job_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
